26 templated_functions_MULTI_TIME
# Name Calls Subrs Excl Incl ProfileCalls # <metadata><attribute><name>Metric Name</name><value>TIME</value></attribute><attribute><name>CPU MHz</name><value>2593.696</value></attribute><attribute><name>Hostname</name><value>node067</value></attribute><attribute><name>MPI Processor Name</name><value>node067</value></attribute><attribute><name>Node Name</name><value>node067</value></attribute><attribute><name>Starting Timestamp</name><value>1385144802464621</value></attribute><attribute><name>Timestamp</name><value>1385144802464796</value></attribute><attribute><name>pid</name><value>15757</value></attribute></metadata>
"int main(int, char **) C [{d2q9-bgk.c} {126,1}-{215,1}]  " 1 20011 27130 11852021 0 GROUP="TAU_DEFAULT" 
"MPI_Init()  " 1 0 1370287 1370287 0 GROUP="MPI" 
"MPI_Comm_size()  " 1 0 1 1 0 GROUP="MPI" 
"MPI_Comm_rank()  " 1 0 1 1 0 GROUP="MPI" 
"int initialise(const char *, const char *, t_param *, t_speed **, t_speed **, int **, float **, int, int, int *) C [{d2q9-bgk.c} {421,1}-{666,1}]  " 1 30 282 1127739 0 GROUP="TAU_USER" 
"MPI_Address()  " 10 0 15 15 0 GROUP="MPI" 
"MPI_Type_create_struct()" 3 0 35 35 0 GROUP="MPI" 
"MPI_Type_commit()  " 3 0 15 15 0 GROUP="MPI" 
"MPI_Bcast()  " 1 0 1087585 1087585 0 GROUP="MPI" 
"MPI_Type_free()  " 3 0 25 25 0 GROUP="MPI" 
"MPI_Recv()  " 13 0 39799 39799 0 GROUP="MPI" 
"int timestep(const t_param, t_speed *, t_speed *, int *, int, int, MPI_Datatype) C [{d2q9-bgk.c} {217,1}-{225,1}]  " 10000 40000 66991 8648920 0 GROUP="TAU_USER" 
"int accelerate_flow(const t_param, t_speed *, int *) C [{d2q9-bgk.c} {227,1}-{257,1}]  " 10000 0 14337 14337 0 GROUP="TAU_USER" 
"int synchronise(const t_param, t_speed *, int, int, MPI_Datatype, MPI_Request *, MPI_Request *, MPI_Request *, MPI_Request *) C [{d2q9-bgk.c} {259,1}-{275,1}]  " 10000 40000 64850 167709 0 GROUP="TAU_USER" 
"MPI_Irecv()  " 20000 0 28894 28894 0 GROUP="MPI" 
"MPI_Isend()  " 20000 0 73965 73965 0 GROUP="MPI" 
"int propagate(const t_param, t_speed *, t_speed *, int, int, MPI_Request *, MPI_Request *, MPI_Request *, MPI_Request *) C [{d2q9-bgk.c} {277,1}-{313,1}]  " 10000 40000 1015339 4738676 0 GROUP="TAU_USER" 
"MPI_Wait()  " 40000 0 3723337 3723337 0 GROUP="MPI" 
"int rebound_or_collision(const t_param, t_speed *, t_speed *, int *) C [{d2q9-bgk.c} {315,1}-{419,1}]  " 10000 0 3661207 3661207 0 GROUP="TAU_USER" 
"float av_velocity(const t_param, t_speed *, int *, int, int, MPI_Datatype) C [{d2q9-bgk.c} {689,1}-{729,1}]  " 10001 20002 442970 504420 0 GROUP="TAU_USER" 
"MPI_Reduce()  " 20002 0 61450 61450 0 GROUP="MPI" 
"float calc_reynolds(const t_param, t_speed *, int *, int, int, MPI_Datatype) C [{d2q9-bgk.c} {731,1}-{736,1}]  " 1 1 2 50 0 GROUP="TAU_USER" 
"int write_values(const t_param, t_speed *, int *, float *, int, int, int) C [{d2q9-bgk.c} {755,1}-{858,1}]  " 1 4 115 2527 0 GROUP="TAU_USER" 
"MPI_Gatherv()  " 4 0 2412 2412 0 GROUP="MPI" 
"int finalise(const t_param *, t_speed **, t_speed **, int **, float **) C [{d2q9-bgk.c} {668,1}-{687,1}]  " 1 0 2 2 0 GROUP="TAU_USER" 
"MPI_Finalize()  " 1 0 170975 170975 0 GROUP="MPI" 
0 aggregates
2 userevents
# eventname numevents max min mean sumsqr
"Message size for broadcast" 1 28 28 28 784
"Message size for reduce" 20002 4 4 4 320032
